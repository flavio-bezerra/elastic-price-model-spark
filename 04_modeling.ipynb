{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo 4: Modelagem e Experimentação (MLflow)\n",
    "\n",
    "## Objetivo\n",
    "Testar diversos algoritmos e hiperparâmetros usando Cross-Validation e registrar os experimentos no MLflow.\n",
    "\n",
    "**Etapas:**\n",
    "1. Setup e Leitura dos Dados\n",
    "2. Feature Engineering (Pipeline)\n",
    "3. Definição dos Modelos e Grids\n",
    "4. Loop de Treinamento e Log no MLflow\n",
    "5. Análise do Melhor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lag, month, year, when\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor, RandomForestRegressor, LinearRegression, DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import datetime\n",
    "\n",
    "# Initialize Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RetailPriceFeatures\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"spark-warehouse\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# MLflow Setup (Adjust experiment name for Databricks)\n",
    "experiment_name = \"/Shared/RetailPrice_Elasticity_Experiment\"\n",
    "try:\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "except:\n",
    "    print(\"Experiment might already exist or local context.\")\n",
    "\n",
    "# Load Data\n",
    "try:\n",
    "    df = spark.table(\"retail_price_clean\")\n",
    "except:\n",
    "    # Fallback for local run without hive\n",
    "    import pandas as pd\n",
    "    df = spark.createDataFrame(pd.read_parquet('../data/retail_price_clean.parquet'))\n",
    "\n",
    "print(f\"Rows: {df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FEATURE ENGINEERING ---\n",
    "# (Mesma lógica do notebook anterior, garantindo consistência)\n",
    "\n",
    "# 1. Lags\n",
    "window_spec = Window.partitionBy(\"product_id\").orderBy(\"date\")\n",
    "df = df.withColumn(\"lag_qty_1\", lag(\"qty\", 1).over(window_spec)) \\\n",
    "       .withColumn(\"lag_price_1\", lag(\"unit_price\", 1).over(window_spec))\n",
    "\n",
    "df = df.na.fill(0)\n",
    "\n",
    "# 2. Features Derivadas\n",
    "df = df.withColumn(\"price_diff_comp1\", col(\"unit_price\") - col(\"comp_1\")) \\\n",
    "       .withColumn(\"month\", month(\"date\"))\n",
    "\n",
    "# 3. Encoding Stages\n",
    "indexer_prod = StringIndexer(inputCol=\"product_id\", outputCol=\"product_id_idx\", handleInvalid=\"keep\")\n",
    "indexer_cat = StringIndexer(inputCol=\"product_category_name\", outputCol=\"product_category_idx\", handleInvalid=\"keep\")\n",
    "encoder_cat = OneHotEncoder(inputCols=[\"product_category_idx\"], outputCols=[\"product_category_vec\"])\n",
    "\n",
    "# 4. Assembler\n",
    "num_features = [\n",
    "    'freight_price', 'unit_price', 'product_name_lenght', 'product_description_lenght',\n",
    "    'product_photos_qty', 'product_weight_g', 'product_score', 'customers',\n",
    "    'weekday', 'weekend', 'holiday', 'month', 'year', 'volume',\n",
    "    'comp_1', 'ps1', 'fp1', 'comp_2', 'ps2', 'fp2', \n",
    "    'comp_3', 'ps3', 'fp3', 'lag_price', \n",
    "    'lag_qty_1', 'lag_price_1', 'price_diff_comp1'\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=num_features + [\"product_id_idx\", \"product_category_vec\"],\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"keep\"\n",
    ")\n",
    "\n",
    "# Split Train/Test\n",
    "dates = df.select(\"date\").distinct().orderBy(\"date\").collect()\n",
    "split_idx = int(len(dates) * 0.8)\n",
    "split_date = dates[split_idx][0]\n",
    "train_df = df.filter(col(\"date\") < split_date)\n",
    "test_df = df.filter(col(\"date\") >= split_date)\n",
    "\n",
    "print(f\"Train: {train_df.count()}, Test: {test_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DEFINIÇÃO DOS MODELOS ---\n",
    "\n",
    "# Avaliador\n",
    "evaluator = RegressionEvaluator(labelCol=\"qty\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "# 1. GBT Regressor\n",
    "gbt = GBTRegressor(featuresCol=\"features\", labelCol=\"qty\", seed=42)\n",
    "grid_gbt = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxDepth, [3, 5]) \\\n",
    "    .addGrid(gbt.maxIter, [20, 50]) \\\n",
    "    .build()\n",
    "\n",
    "# 2. Random Forest\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"qty\", seed=42)\n",
    "grid_rf = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [20, 50]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "# 3. Linear Regression (Baseline)\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"qty\")\n",
    "grid_lr = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.0, 0.1]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5]) \\\n",
    "    .build()\n",
    "\n",
    "models_to_run = [\n",
    "    (\"GBT\", gbt, grid_gbt),\n",
    "    (\"RandomForest\", rf, grid_rf),\n",
    "    (\"LinearRegression\", lr, grid_lr)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LOOP DE TREINAMENTO ---\n",
    "\n",
    "def train_and_log(name, model, param_grid):\n",
    "    with mlflow.start_run(run_name=f\"Train_{name}\"):\n",
    "        print(f\"Training {name}...\")\n",
    "        \n",
    "        # Pipeline specific for this model\n",
    "        # Note: Indexers/Assembler are stateless estimators or transformers, can be reused\n",
    "        pipeline = Pipeline(stages=[indexer_prod, indexer_cat, encoder_cat, assembler, model])\n",
    "        \n",
    "        # Cross Validator\n",
    "        cv = CrossValidator(estimator=pipeline,\n",
    "                            estimatorParamMaps=param_grid,\n",
    "                            evaluator=evaluator,\n",
    "                            numFolds=3, seed=42)\n",
    "        \n",
    "        # Fit\n",
    "        cv_model = cv.fit(train_df)\n",
    "        best_model = cv_model.bestModel\n",
    "        \n",
    "        # Metrics on Test Data (Holdout)\n",
    "        predictions = best_model.transform(test_df)\n",
    "        rmse = evaluator.evaluate(predictions)\n",
    "        r2 = RegressionEvaluator(labelCol=\"qty\", predictionCol=\"prediction\", metricName=\"r2\").evaluate(predictions)\n",
    "        \n",
    "        print(f\"  -> RMSE: {rmse:.4f}, R2: {r2:.4f}\")\n",
    "        \n",
    "        # Log MLflow\n",
    "        mlflow.log_param(\"model_type\", name)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        \n",
    "        # Log Params of Best Model\n",
    "        # Extracting params from the last stage (the model itself)\n",
    "        model_stage = best_model.stages[-1]\n",
    "        # Simple logging of a few key params manually for clarity (or automate extraction)\n",
    "        if name == \"GBT\":\n",
    "            mlflow.log_param(\"maxDepth\", model_stage.getMaxDepth())\n",
    "            mlflow.log_param(\"maxIter\", model_stage.getMaxIter())\n",
    "        elif name == \"RandomForest\":\n",
    "            mlflow.log_param(\"numTrees\", model_stage.getNumTrees())\n",
    "            mlflow.log_param(\"maxDepth\", model_stage.getMaxDepth())\n",
    "            \n",
    "        # Save Best Model Artifact\n",
    "        mlflow.spark.log_model(best_model, \"model\")\n",
    "        \n",
    "        return name, rmse, best_model\n",
    "\n",
    "results = []\n",
    "for name, model, grid in models_to_run:\n",
    "    res = train_and_log(name, model, grid)\n",
    "    results.append(res)\n",
    "\n",
    "# Find Winner\n",
    "results.sort(key=lambda x: x[1]) # Sort by RMSE asc\n",
    "winner_name, winner_rmse, winner_model = results[0]\n",
    "\n",
    "print(f\"\\nWINNER MODEL: {winner_name} with RMSE: {winner_rmse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
